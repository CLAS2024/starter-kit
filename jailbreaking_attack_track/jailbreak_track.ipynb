{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Import packages"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4151a0b49b1c4cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading original prompts (\"prompt_develop.jsonl\") and your jailbreak prompts (\"jailbreak_develop.jsonl\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db071cae48b7359e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_prompts(file_name):\n",
    "    prompt_list = []\n",
    "    with open(file_name, 'r') as file:\n",
    "        for line in file:\n",
    "            json_record = json.loads(line)\n",
    "            prompt_list.append(json_record[\"prompt\"])\n",
    "    return prompt_list\n",
    "original_prompt_list = get_prompts(file_name=\"prompt_test.jsonl\") # prompt in test phase\n",
    "jailbreak_prompt_list = get_prompts(file_name=\"./submission/jailbreak_test.jsonl\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a05f1715d3bfefe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading model inference pipeline"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5accfaab0fc39d0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_model_inference_pipeline(model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=512)\n",
    "    return pipe\n",
    "model_id = \"google/gemma-2b-it\" # one test-phase model (we also hold another LLM for test)\n",
    "pipe = get_model_inference_pipeline(model_id)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d474f8570988e9c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading functions to compute jailbreak scores and stealthiness scores"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca5f15ceccdc103f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils import get_jailbreak_score\n",
    "from utils import get_stl_score"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea92c08f1a227050"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Peform model inference with jailbreak prompts and evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c98f4a048f6b1d88"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = []\n",
    "avg_jailbreak_score, avg_stealthiness_score = 0., 0.\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "for original_prompt, jailbreak_prompt in tqdm(zip(original_prompt_list, jailbreak_prompt_list)):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": jailbreak_prompt},\n",
    "    ]\n",
    "    response = pipe(messages)[0]['generated_text'][1]['content']\n",
    "    jailbreak_score = get_jailbreak_score(pipe, original_prompt, jailbreak_prompt, response, tokenizer)\n",
    "    stl_score = get_stl_score(original_prompt, jailbreak_prompt)\n",
    "    record = {\"original_prompt\": original_prompt, \"jailbreak_prompt\": jailbreak_prompt, \"response\": response, \"jailbreak_score\": jailbreak_score, \"stealthiness_score\": stl_score}\n",
    "    results.append(record)\n",
    "    avg_jailbreak_score += jailbreak_score / len(jailbreak_prompt_list)\n",
    "    avg_stealthiness_score += stl_score / len(jailbreak_prompt_list)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e72c8bae9618217e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Store and show final results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34cb7112879469a5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_name = \"results_test.jsonl\"\n",
    "with open(file_name, 'w') as file:\n",
    "    for dictionary in results:\n",
    "        json_record = json.dumps(dictionary)\n",
    "        file.write(json_record + \"\\n\")\n",
    "print(f'Average jailbreak score: {avg_jailbreak_score}') # 0.151 for PAP jailbreak\n",
    "print(f'Average stealthiness score: {avg_stealthiness_score}') # 0.220 for PAP jailbreak"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a17224dda01e45d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
